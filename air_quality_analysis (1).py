# -*- coding: utf-8 -*-
"""Air Quality Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H__S-JoFpXjZNsWjsTe4hkNb_oif12IP
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, max, min, to_date, month

spark = SparkSession.builder \
    .appName("India Air Quality Analysis") \
    .getOrCreate()

df = spark.read.csv("/content/city_day.csv", header=True, inferSchema=True)
df.show(5)

from pyspark.sql.functions import col, sum as spark_sum

# Replace dots or spaces in column names with underscores
df = df.toDF(*[c.replace('.', '_').replace(' ', '_') for c in df.columns])
df.show(5)

from pyspark.sql.functions import col, sum as spark_sum

missing_values = df.select([
    spark_sum(col(c).isNull().cast("int")).alias(c)
    for c in df.columns
])
missing_values.show()

df = df.withColumn("Datetime", to_date(col("Datetime"), "yyyy-MM-dd"))

df.groupBy("city") \
  .agg(avg("aqi").alias("avg_aqi")) \
  .orderBy(col("avg_aqi").desc()) \
  .show()

df = df.withColumn("month", month(col("Datetime")))

monthly_avg = df.groupBy("month") \
                .agg(avg("pm2_5").alias("avg_pm2_5"),
                     avg("pm10").alias("avg_pm10"),
                     avg("no2").alias("avg_no2")) \
                .orderBy("month")

monthly_avg.show()

# Correlation example
df.select("pm2_5","aqi").stat.corr("pm2_5","aqi")

import matplotlib.pyplot as plt

monthly_avg_pd = monthly_avg.toPandas()
monthly_avg_pd.plot(x="month", y=["avg_pm2_5","avg_pm10","avg_no2"], kind="line")
plt.title("Monthly Air Quality Trends")
plt.show()

from pyspark.sql.functions import year

df = df.withColumn("year", year(col("Datetime")))

yearly_avg = df.groupBy("year").agg(
    avg("pm2_5").alias("avg_pm2_5"),
    avg("pm10").alias("avg_pm10"),
    avg("aqi").alias("avg_aqi")
).orderBy("year")

yearly_avg.show()

# Visualization
yearly_avg_pd = yearly_avg.toPandas()
yearly_avg_pd.plot(x="year", y=["avg_pm2_5","avg_pm10","avg_aqi"], kind="line", title="Yearly Pollution Trend")
plt.show()

for pollutant in ["pm2_5","pm10","no2","so2","co","o3"]:
    top_city = df.groupBy("city") \
                 .agg(avg(col(pollutant)).alias(f"avg_{pollutant}")) \
                 .orderBy(col(f"avg_{pollutant}").desc()) \
                 .limit(5)
    print(f"Top 5 cities for {pollutant.upper()}")
    top_city.show()

from pyspark.sql.functions import when

df = df.withColumn("season",
    when((col("month").isin(12,1,2)), "Winter")
    .when((col("month").isin(3,4,5)), "Summer")
    .when((col("month").isin(6,7,8,9)), "Monsoon")
    .otherwise("Post-Monsoon")
)

seasonal_avg = df.groupBy("season").agg(
    avg("pm2_5").alias("avg_pm2_5"),
    avg("pm10").alias("avg_pm10"),
    avg("aqi").alias("avg_aqi")
).orderBy("season")

seasonal_avg.show()

# Visualization
seasonal_avg_pd = seasonal_avg.toPandas()
seasonal_avg_pd.plot(x="season", y=["avg_pm2_5","avg_pm10","avg_aqi"], kind="bar", title="Seasonal Air Quality")
plt.show()

pollutants = ["pm2_5","pm10","no2","so2","co","o3"]
corr_data = {p: [] for p in pollutants}

for i in pollutants:
    for j in pollutants:
        corr = df.select(i, j).stat.corr(i, j)
        corr_data[i].append(round(corr, 3))

import pandas as pd
corr_df = pd.DataFrame(corr_data, index=pollutants)
print(corr_df)

best_day = df.orderBy(col("aqi").asc()).limit(1)
worst_day = df.orderBy(col("aqi").desc()).limit(1)

print("Best Air Quality Day:")
best_day.show()

print("Worst Air Quality Day:")
worst_day.show()

df = df.withColumn("AQI_Level",
    when(col("aqi") <= 50, "Good")
    .when((col("aqi") > 50) & (col("aqi") <= 100), "Satisfactory")
    .when((col("aqi") > 100) & (col("aqi") <= 200), "Moderate")
    .when((col("aqi") > 200) & (col("aqi") <= 300), "Poor")
    .when((col("aqi") > 300) & (col("aqi") <= 400), "Very Poor")
    .otherwise("Severe")
)

df.groupBy("AQI_Level").count().orderBy("count", ascending=False).show()
# Go to your repository folder
cd path/to/india-air-quality-analysis
